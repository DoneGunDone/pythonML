{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"# Логистическая регрессия\\n\",\n",
    "        \"Описание логистическую регрессию для предсказания того, отнёсется ли клиент на рекламе предложенные (target = 1) или нет (target = 0).\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## Получение библиотеки, загрузка и обзор данных\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"import matplotlib.pyplot as plt\\n\",\n",
    "        \"import pandas as pd\\n\",\n",
    "        \"import numpy as np\\n\",\n",
    "        \"import seaborn as sns\\n\",\n",
    "        \"from sklearn.model_selection import train_test_split\\n\",\n",
    "        \"from sklearn.preprocessing import StandardScaler\\n\",\n",
    "        \"from sklearn.linear_model import LogisticRegression\\n\",\n",
    "        \"from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix\\n\",\n",
    "        \"import warnings\\n\",\n",
    "        \"warnings.filterwarnings('ignore')\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Загрузка данных\\n\",\n",
    "        \"data = pd.read_csv('https://raw.githubusercontent.com/evgpat/edu_stepik_practical_ml/main/datasets/clients_data.csv')\\n\",\n",
    "        \"data.head()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Разделяем данные\\n\",\n",
    "        \"X = data.drop(['ID', 'TARGET'], axis=1)  # Исправлено: добавляем ID в список столбцов для удаления\\n\",\n",
    "        \"y = data['TARGET']\\n\",\n",
    "        \"\\n\",\n",
    "        \"Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=0.7, random_state=123)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## Практика\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Задание\\n\",\n",
    "        \"Задание на скольки объектов какого класса. Сколько подлогов обновляют к положительному классу?  \\n\",\n",
    "        \"Ответ округлите до целого числа (например, если доля объектов положительного класса 41.2, а ответ салют 41).\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Подсчёт количества объектов каждого класса\\n\",\n",
    "        \"class_counts = pd.Series(ytrain).value_counts()\\n\",\n",
    "        \"print(\\\"Количество объектов класса 0 (отрицательный):\\\", class_counts[0])\\n\",\n",
    "        \"print(\\\"Количество объектов класса 1 (положительный):\\\", class_counts[1])\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Доля положительного класса\\n\",\n",
    "        \"positive_class_ratio = class_counts[1] / len(ytrain)\\n\",\n",
    "        \"print(\\\"Доля положительного класса:\\\", positive_class_ratio)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Округлённая доля в процентах\\n\",\n",
    "        \"positive_class_percentage = round(positive_class_ratio * 100)\\n\",\n",
    "        \"print(\\\"Доля положительного класса (в процентах, округлённая):\\\", positive_class_percentage)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Обучение логистическую регрессию с параметром поумолчанию\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Масштабируем данные (важно для логистической регрессии)\\n\",\n",
    "        \"scaler = StandardScaler()\\n\",\n",
    "        \"Xtrain_scaled = scaler.fit_transform(Xtrain)\\n\",\n",
    "        \"Xtest_scaled = scaler.transform(Xtest)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Обучаем модель\\n\",\n",
    "        \"lr = LogisticRegression(random_state=42, max_iter=1000)\\n\",\n",
    "        \"lr.fit(Xtrain_scaled, ytrain)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Предсказываем\\n\",\n",
    "        \"prediction = lr.predict(Xtest_scaled)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"Метрика accuracy не устойчивая при сильном дисбалансе классов. Поэтому посчитайте f1_score для оценки качества. Получите посчитайте f1_score для оценки качества. f1_score принимает значения от 0 до 1. Чем ближе к 1, тем лучше модель.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"from sklearn.metrics import f1_score\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Считаем f1_score\\n\",\n",
    "        \"f1 = f1_score(ytest, prediction)\\n\",\n",
    "        \"print(\\\"f1_score модели:\\\", f1)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"**Вопрос f1_score?**  \\n\",\n",
    "        \"Ответ: Значение f1_score ты увидишь после выполнения кода. Например, если f1_score = 0.35, это значит, что модель плохо справляется с классификацией положительного класса, скорее всего из-за дисбаланса.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"**Задание разделяется, почему качество такое низкое.**\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"Качество низкое из-за:\\n\",\n",
    "        \"- **Дисбаланса классов:** Положительного класса (TARGET = 1) намного меньше, чем отрицательного. Модель склонна предсказывать доминирующий класс (0), что снижает f1_score.\\n\",\n",
    "        \"- **Отсутствие масштабирования:** Ты изначально не масштабировал данные, а логистическая регрессия чувствительна к масштабу признаков. Мы это исправили, добавив `StandardScaler`.\\n\",\n",
    "        \"- **Дефолтный порог:** Порог 0.5 для классификации может быть неоптимальным при дисбалансе.\\n\",\n",
    "        \"- **Признаки:** Некоторые признаки могут быть неинформативными.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"**Проверка разделяемости с помощью линейных разделяемых.**\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Получаем вероятности\\n\",\n",
    "        \"probs_test = lr.predict_proba(Xtest_scaled)[:, 1]\\n\",\n",
    "        \"print(\\\"Первые 18 вероятностей:\\\")\\n\",\n",
    "        \"print(probs_test[:18])\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Визуализируем распределение вероятностей\\n\",\n",
    "        \"plt.figure(figsize=(8, 5))\\n\",\n",
    "        \"plt.hist(probs_test[ytest == 0], bins=30, alpha=0.5, label='Класс 0', color='blue')\\n\",\n",
    "        \"plt.hist(probs_test[ytest == 1], bins=30, alpha=0.5, label='Класс 1', color='orange')\\n\",\n",
    "        \"plt.xlabel('Вероятность класса 1')\\n\",\n",
    "        \"plt.ylabel('Количество')\\n\",\n",
    "        \"plt.title('Распределение вероятностей')\\n\",\n",
    "        \"plt.legend()\\n\",\n",
    "        \"plt.show()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"**По порогами вышло, что вероятность отнесения к положительному классу очень низкая.**  \\n\",\n",
    "        \"Да, вероятности для класса 1 низкие, потому что классы несбалансированы, и модель склонна предсказывать класс 0. Мы можем улучшить это, подобрав порог.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"**Попросил раздельные минимальное на train данных Xtrain, Xval, Xtest.**\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Разделяем Xtrain на Xtrain_new и Xval\\n\",\n",
    "        \"Xtrain_new, Xval, ytrain_new, yval = train_test_split(Xtrain_scaled, ytrain, train_size=0.7, random_state=123)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"**Неужели равны f1_score, если бы всё-таки с вероятностью не меняя 0.1, отнёс к положительному классу?**  \\n\",\n",
    "        \"**Ответ округлите до двух.**\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Применяем порог 0.1\\n\",\n",
    "        \"new_predictions = (probs_test >= 0.1).astype(int)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Считаем f1_score с новым порогом\\n\",\n",
    "        \"f1_new = f1_score(ytest, new_predictions)\\n\",\n",
    "        \"print(\\\"f1_score с порогом 0.1:\\\", round(f1_new, 2))\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"**Улучшение модели можно посмотреть веса (как в линейной регрессии).**\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Исправляем код для весов\\n\",\n",
    "        \"weights_lr = pd.DataFrame({'coef': lr.coef_[0]},\\n\",\n",
    "        \"                          index=data.drop(['ID', 'TARGET'], axis=1).columns.tolist())\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Добавляем intercept\\n\",\n",
    "        \"weights_lr.loc['intercept'] = lr.intercept_[0]\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Сортируем по убыванию\\n\",\n",
    "        \"weights_lr = weights_lr.sort_values(by='coef', ascending=False)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Выводим таблицу\\n\",\n",
    "        \"print(weights_lr)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"**Вопрос: Какой признак имеет наибольший положительный вес?**\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"top_feature = weights_lr.index[0]\\n\",\n",
    "        \"print(\\\"Признак с наибольшим положительным весом:\\\", top_feature)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## Бонус\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Задание 1\\n\",\n",
    "        \"Подайте 1 порог для перевода вероятности в классы, дающий максимальное значение f1_score.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Перебираем пороги на валидационной выборке\\n\",\n",
    "        \"probs_val = lr.predict_proba(Xval)[:, 1]\\n\",\n",
    "        \"thresholds = np.arange(0.05, 0.95, 0.05)\\n\",\n",
    "        \"f1_scores = []\\n\",\n",
    "        \"\\n\",\n",
    "        \"for thresh in thresholds:\\n\",\n",
    "        \"    val_predictions = (probs_val >= thresh).astype(int)\\n\",\n",
    "        \"    f1 = f1_score(yval, val_predictions)\\n\",\n",
    "        \"    f1_scores.append(f1)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Находим порог с максимальным f1_score\\n\",\n",
    "        \"best_threshold = thresholds[np.argmax(f1_scores)]\\n\",\n",
    "        \"best_f1 = max(f1_scores)\\n\",\n",
    "        \"print(\\\"Лучший порог:\\\", best_threshold)\\n\",\n",
    "        \"print(\\\"Максимальный f1_score на валидационной выборке:\\\", best_f1)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Визуализируем зависимость f1_score от порога\\n\",\n",
    "        \"plt.figure(figsize=(8, 5))\\n\",\n",
    "        \"plt.plot(thresholds, f1_scores, marker='o')\\n\",\n",
    "        \"plt.xlabel('Порог')\\n\",\n",
    "        \"plt.ylabel('f1_score')\\n\",\n",
    "        \"plt.title('Зависимость f1_score от порога')\\n\",\n",
    "        \"plt.grid(True)\\n\",\n",
    "        \"plt.show()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Задание 2\\n\",\n",
    "        \"Восстановим в классы, дайте оценку максимильную у логистической регрессии и порог для перевода вероятностей в классы с учётической регрессии и порог для перевода.\\n\",\n",
    "        \"\\n\",\n",
    "        \"Поэтому разделим данные на train части Xtrain, Xval, Xtest.\\n\",\n",
    "        \"- В цикле при пороге с и порога будем обучаться по Xtrain, а предсказывать измерять качество по Xval.\\n\",\n",
    "        \"- Качество итоговой модели с найденным с и порогом измерять по Xtest.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Перебираем параметр C и порог\\n\",\n",
    "        \"C_values = [0.01, 0.1, 1, 10, 100]\\n\",\n",
    "        \"thresholds = np.arange(0.05, 0.95, 0.05)\\n\",\n",
    "        \"best_C = None\\n\",\n",
    "        \"best_threshold = None\\n\",\n",
    "        \"best_f1 = 0\\n\",\n",
    "        \"\\n\",\n",
    "        \"for C in C_values:\\n\",\n",
    "        \"    model = LogisticRegression(C=C, random_state=42, max_iter=1000)\\n\",\n",
    "        \"    model.fit(Xtrain_new, ytrain_new)\\n\",\n",
    "        \"    probs_val = model.predict_proba(Xval)[:, 1]\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    for thresh in thresholds:\\n\",\n",
    "        \"        val_predictions = (probs_val >= thresh).astype(int)\\n\",\n",
    "        \"        f1 = f1_score(yval, val_predictions)\\n\",\n",
    "        \"        if f1 > best_f1:\\n\",\n",
    "        \"            best_f1 = f1\\n\",\n",
    "        \"            best_C = C\\n\",\n",
    "        \"            best_threshold = thresh\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"Лучший параметр C:\\\", best_C)\\n\",\n",
    "        \"print(\\\"Лучший порог:\\\", best_threshold)\\n\",\n",
    "        \"print(\\\"Максимальный f1_score на валидационной выборке:\\\", best_f1)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Обучаем итоговую модель на всех тренировочных данных\\n\",\n",
    "        \"final_model = LogisticRegression(C=best_C, random_state=42, max_iter=1000)\\n\",\n",
    "        \"final_model.fit(Xtrain_scaled, ytrain)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Предсказываем на тестовых данных\\n\",\n",
    "        \"probs_test = final_model.predict_proba(Xtest_scaled)[:, 1]\\n\",\n",
    "        \"final_predictions = (probs_test >= best_threshold).astype(int)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Оцениваем качество на тестовых данных\\n\",\n",
    "        \"final_f1 = f1_score(ytest, final_predictions)\\n\",\n",
    "        \"print(\\\"f1_score на тестовых данных:\\\", final_f1)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Выводим матрицу ошибок\\n\",\n",
    "        \"conf_matrix = confusion_matrix(ytest, final_predictions)\\n\",\n",
    "        \"plt.figure(figsize=(6, 4))\\n\",\n",
    "        \"sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\\n\",\n",
    "        \"            xticklabels=['Класс 0', 'Класс 1'], yticklabels=['Класс 0', 'Класс 1'])\\n\",\n",
    "        \"plt.xlabel('Предсказанный класс')\\n\",\n",
    "        \"plt.ylabel('Реальный класс')\\n\",\n",
    "        \"plt.title('Матрица ошибок')\\n\",\n",
    "        \"plt.show()\"\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"kernelspec\": {\n",
    "      \"display_name\": \"Python 3\",\n",
    "      \"language\": \"python\",\n",
    "      \"name\": \"python3\"\n",
    "    },\n",
    "    \"language_info\": {\n",
    "      \"codemirror_mode\": {\n",
    "        \"name\": \"ipython\",\n",
    "        \"version\": 3\n",
    "      },\n",
    "      \"file_extension\": \".py\",\n",
    "      \"mimetype\": \"text/x-python\",\n",
    "      \"name\": \"python\",\n",
    "      \"nbconvert_exporter\": \"python\",\n",
    "      \"pygments_lexer\": \"ipython3\",\n",
    "      \"version\": \"3.8.5\"\n",
    "    }\n",
    "  },\n",
    "  \"nbformat\": 4,\n",
    "  \"nbformat_minor\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получение библиотеки, загрузка и обзор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/evgpat/edu_stepik_practical_ml/main/datasets/clients_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем данные\n",
    "X = data.drop(['ID', 'TARGET'], axis=1)  # Исправлено: добавляем ID в список столбцов для удаления\n",
    "y = data['TARGET']\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=0.7, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание\n",
    "Задание на скольки объектов какого класса. Сколько подлогов обновляют к положительному классу?  \n",
    "Ответ округлите до целого числа (например, если доля объектов положительного класса 41.2, а ответ салют 41)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подсчёт количества объектов каждого класса\n",
    "class_counts = pd.Series(ytrain).value_counts()\n",
    "print(\"Количество объектов класса 0 (отрицательный):\", class_counts[0])\n",
    "print(\"Количество объектов класса 1 (положительный):\", class_counts[1])\n",
    "\n",
    "# Доля положительного класса\n",
    "positive_class_ratio = class_counts[1] / len(ytrain)\n",
    "print(\"Доля положительного класса:\", positive_class_ratio)\n",
    "\n",
    "# Округлённая доля в процентах\n",
    "positive_class_percentage = round(positive_class_ratio * 100)\n",
    "print(\"Доля положительного класса (в процентах, округлённая):\", positive_class_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение логистическую регрессию с параметром поумолчанию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Масштабируем данные (важно для логистической регрессии)\n",
    "scaler = StandardScaler()\n",
    "Xtrain_scaled = scaler.fit_transform(Xtrain)\n",
    "Xtest_scaled = scaler.transform(Xtest)\n",
    "\n",
    "# Обучаем модель\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(Xtrain_scaled, ytrain)\n",
    "\n",
    "# Предсказываем\n",
    "prediction = lr.predict(Xtest_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика accuracy не устойчивая при сильном дисбалансе классов. Поэтому посчитайте f1_score для оценки качества. Получите посчитайте f1_score для оценки качества. f1_score принимает значения от 0 до 1. Чем ближе к 1, тем лучше модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Считаем f1_score\n",
    "f1 = f1_score(ytest, prediction)\n",
    "print(\"f1_score модели:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос f1_score?**  \n",
    "Ответ: Значение f1_score ты увидишь после выполнения кода. Например, если f1_score = 0.35, это значит, что модель плохо справляется с классификацией положительного класса, скорее всего из-за дисбаланса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание разделяется, почему качество такое низкое.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество низкое из-за:\n",
    "- **Дисбаланса классов:** Положительного класса (TARGET = 1) намного меньше, чем отрицательного. Модель склонна предсказывать доминирующий класс (0), что снижает f1_score.\n",
    "- **Отсутствие масштабирования:** Ты изначально не масштабировал данные, а логистическая регрессия чувствительна к масштабу признаков. Мы это исправили, добавив `StandardScaler`.\n",
    "- **Дефолтный порог:** Порог 0.5 для классификации может быть неоптимальным при дисбалансе.\n",
    "- **Признаки:** Некоторые признаки могут быть неинформативными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверка разделяемости с помощью линейных разделяемых.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем вероятности\n",
    "probs_test = lr.predict_proba(Xtest_scaled)[:, 1]\n",
    "print(\"Первые 18 вероятностей:\")\n",
    "print(probs_test[:18])\n",
    "\n",
    "# Визуализируем распределение вероятностей\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(probs_test[ytest == 0], bins=30, alpha=0.5, label='Класс 0', color='blue')\n",
    "plt.hist(probs_test[ytest == 1], bins=30, alpha=0.5, label='Класс 1', color='orange')\n",
    "plt.xlabel('Вероятность класса 1')\n",
    "plt.ylabel('Количество')\n",
    "plt.title('Распределение вероятностей')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**По порогами вышло, что вероятность отнесения к положительному классу очень низкая.**  \n",
    "Да, вероятности для класса 1 низкие, потому что классы несбалансированы, и модель склонна предсказывать класс 0. Мы можем улучшить это, подобрав порог."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Попросил раздельные минимальное на train данных Xtrain, Xval, Xtest.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем Xtrain на Xtrain_new и Xval\n",
    "Xtrain_new, Xval, ytrain_new, yval = train_test_split(Xtrain_scaled, ytrain, train_size=0.7, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Неужели равны f1_score, если бы всё-таки с вероятностью не меняя 0.1, отнёс к положительному классу?**  \n",
    "**Ответ округлите до двух.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применяем порог 0.1\n",
    "new_predictions = (probs_test >= 0.1).astype(int)\n",
    "\n",
    "# Считаем f1_score с новым порогом\n",
    "f1_new = f1_score(ytest, new_predictions)\n",
    "print(\"f1_score с порогом 0.1:\", round(f1_new, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Улучшение модели можно посмотреть веса (как в линейной регрессии).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исправляем код для весов\n",
    "weights_lr = pd.DataFrame({'coef': lr.coef_[0]},\n",
    "                          index=data.drop(['ID', 'TARGET'], axis=1).columns.tolist())\n",
    "\n",
    "# Добавляем intercept\n",
    "weights_lr.loc['intercept'] = lr.intercept_[0]\n",
    "\n",
    "# Сортируем по убыванию\n",
    "weights_lr = weights_lr.sort_values(by='coef', ascending=False)\n",
    "\n",
    "# Выводим таблицу\n",
    "print(weights_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос: Какой признак имеет наибольший положительный вес?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feature = weights_lr.index[0]\n",
    "print(\"Признак с наибольшим положительным весом:\", top_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бонус"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "Подайте 1 порог для перевода вероятности в классы, дающий максимальное значение f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перебираем пороги на валидационной выборке\n",
    "probs_val = lr.predict_proba(Xval)[:, 1]\n",
    "thresholds = np.arange(0.05, 0.95, 0.05)\n",
    "f1_scores = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    val_predictions = (probs_val >= thresh).astype(int)\n",
    "    f1 = f1_score(yval, val_predictions)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Находим порог с максимальным f1_score\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "best_f1 = max(f1_scores)\n",
    "print(\"Лучший порог:\", best_threshold)\n",
    "print(\"Максимальный f1_score на валидационной выборке:\", best_f1)\n",
    "\n",
    "# Визуализируем зависимость f1_score от порога\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(thresholds, f1_scores, marker='o')\n",
    "plt.xlabel('Порог')\n",
    "plt.ylabel('f1_score')\n",
    "plt.title('Зависимость f1_score от порога')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "Восстановим в классы, дайте оценку максимильную у логистической регрессии и порог для перевода вероятностей в классы с учётической регрессии и порог для перевода.\n",
    "\n",
    "Поэтому разделим данные на train части Xtrain, Xval, Xtest.\n",
    "- В цикле при пороге с и порога будем обучаться по Xtrain, а предсказывать измерять качество по Xval.\n",
    "- Качество итоговой модели с найденным с и порогом измерять по Xtest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перебираем параметр C и порог\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "thresholds = np.arange(0.05, 0.95, 0.05)\n",
    "best_C = None\n",
    "best_threshold = None\n",
    "best_f1 = 0\n",
    "\n",
    "for C in C_values:\n",
    "    model = LogisticRegression(C=C, random_state=42, max_iter=1000)\n",
    "    model.fit(Xtrain_new, ytrain_new)\n",
    "    probs_val = model.predict_proba(Xval)[:, 1]\n",
    "    \n",
    "    for thresh in thresholds:\n",
    "        val_predictions = (probs_val >= thresh).astype(int)\n",
    "        f1 = f1_score(yval, val_predictions)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_C = C\n",
    "            best_threshold = thresh\n",
    "\n",
    "print(\"Лучший параметр C:\", best_C)\n",
    "print(\"Лучший порог:\", best_threshold)\n",
    "print(\"Максимальный f1_score на валидационной выборке:\", best_f1)\n",
    "\n",
    "# Обучаем итоговую модель на всех тренировочных данных\n",
    "final_model = LogisticRegression(C=best_C, random_state=42, max_iter=1000)\n",
    "final_model.fit(Xtrain_scaled, ytrain)\n",
    "\n",
    "# Предсказываем на тестовых данных\n",
    "probs_test = final_model.predict_proba(Xtest_scaled)[:, 1]\n",
    "final_predictions = (probs_test >= best_threshold).astype(int)\n",
    "\n",
    "# Оцениваем качество на тестовых данных\n",
    "final_f1 = f1_score(ytest, final_predictions)\n",
    "print(\"f1_score на тестовых данных:\", final_f1)\n",
    "\n",
    "# Выводим матрицу ошибок\n",
    "conf_matrix = confusion_matrix(ytest, final_predictions)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Класс 0', 'Класс 1'], yticklabels=['Класс 0', 'Класс 1'])\n",
    "plt.xlabel('Предсказанный класс')\n",
    "plt.ylabel('Реальный класс')\n",
    "plt.title('Матрица ошибок')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

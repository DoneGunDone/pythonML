import torch
import numpy as np

# data = np.array([[1, 2], [3, 4], [5, 6]])

# batch = data[0:2, :]  # Выбираем первые две строки [[1 2] [3 4]]
# tensor = torch.from_numpy(batch).to("mps")  # Преобразуем в тензор и отправляем на MPS
#
# print(tensor) # tensor([[1, 2], [3, 4]], device='mps:0')
#
# data = np.random.rand(1000, 5) # матрица размером 1000x5(1000 строк 5 столбцов)
# print(data)
# labels = np.random.randint(0, 2, 1000) # 1000 строк 1 столбец
# print(labels) # массив из 1000 элементов от 0 до 2 (0 или 1)
# # labels = np.random.randint(0, 2, [100, 2])
# # print(labels.shape)
# # print(labels) # 100 строк 2 столбца, заполненные случайными числами от 0 до 2(0 или 1)
#
#
# train_size = int(0.8 * len(data))
# print(train_size) # len = 1000 => train_size = 800
# train_data = data[:train_size, :] # data от 0 до 799 элемента(убрали 200 последних строк)
# train_labels = labels[:train_size] # режем лейблы от 0 до 799
# test_data = data[train_size:, :] # тестовая дата - последние 200 строк(от 800 до 999 индексы)
# test_labels = labels[train_size:] # тестовые лейблы - последние 200 лейблов(от 800 до 999 индексы)
#
# print(train_data.shape, test_data.shape) # (800, 5) (200, 5)
# print(train_labels.shape, test_labels.shape) # (800,) (200,)

# ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------

## Фильтрация данных с логической индексацией
# Удаление выбросов (значения > 3 стандартных отклонений)
# data = np.random.randn(100, 5)
# print(data) # массив 100 x 5 рандомными числами по нормальному распределению
# print(data.shape) # (100, 5)
#
# mean = np.mean(data, axis=0) # среднее арифметическое по каждому столбцу - [-0.08001262 -0.19659356  0.14587082  0.00173579 -0.0376917 ]
# print(mean) # [-0.10839551  0.0164085   0.14601686  0.02593465 -0.10372712]
# # array = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
# # meann = np.mean(array, axis=0)
# # print("meann:", meann) # 22/4 = 5.5, 26/4 = 6.5, 30/4 = 7.5
# print();print()
#
# std = np.std(data, axis=0) # вычисление стандартного отклонения значений от среднего
# print(std) # [0.89081524 0.98651152 0.94185592 1.03949593 0.84660846] # данные в 4 столбце отклоняются меньше всех(0.847), в 3 столбце больше всех(1.04)
#
# shesh = (data - mean) / std # из каждой строки массива data вычитаем mean, а затем делим на std - Z-оценка(показывает, сколько стандартных отклонений значение находится от среднего)
# print("shesh:", shesh)
# mask = np.all(np.abs((data - mean) / std) < 3, axis=1)  # np.abs нужно для взятие абсолютных значение для каждой оценки, чтобы найти и -4 отклонение и +4
# print(mask) # np.abs((data - mean) / std) < 3 создает булев массив (100, 5), где:
#             # True — если значение находится в пределах 3 стандартных отклонений  ∣Z∣ < 3
#             # False — если значение является выбросом  ∣Z∣ ≥ 3
#
# # Функция np.all проверяет, выполняются ли условия (True) для всех элементов вдоль указанной оси. Здесь axis=1 означает, что проверяется каждая строка
# print(mask.shape) # (100,)
# filtered_data = data[mask] # (очистили данные тех строк, где есть отклонение > 3, то есть стоит false)
# print(filtered_data.shape)  # Меньше, чем (100, 5), если есть выбросы => (99, 5) или 98, 5

# ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------

### Создание батча с фантазийной индексацией
# Случайный батч из 32 образцов
# data = np.random.rand(1000, 10) #
# # print(data)
# print(data.shape) # 1000 x 10 => 1000 строк 10 столбцов чисел от [0 до 1)
# indices = np.random.choice(len(data), size=32, replace=False) # случайно берутся индексы от 0 до 999 и 32 таких случайных индекса помещаются в массив 1xsize
# # print(indices) # например [549 761 547 363 408 492 954 871 184 918 376 439 130 472 810 261 602 726 145 922 863 936  78 550  49 778 216 373 242 960 669 962]
# batch = data[indices, :] # берем эти индексы и заносим данные под индексами соответственно в батч(549 индекс будет первым, 962 индекс последним 31-ым)
# print(batch.shape)  # (32, 10)
# print(batch)

# ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------

### Интеграция с pyTorch

# Подготовка данных с использованием срезов
data = np.random.rand(100, 10).astype(np.float32)  # Устанавливаем float32 для MPS
labels = np.random.randint(0, 2, 100).astype(np.int64)
batch_data = data[0:32, :]  # Батч из первых 32 образцов
batch_labels = labels[0:32]

# Преобразование в тензоры и отправка на MPS
device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
tensor_data = torch.from_numpy(batch_data).to(device)
print("tensor data:", tensor_data)
tensor_labels = torch.from_numpy(batch_labels).to(device)
print("tensor labels:", tensor_labels)
print(tensor_data.shape, tensor_labels.shape)  # torch.Size([32, 10]), torch.Size([32])

print(torch.backends.mps.is_available())
